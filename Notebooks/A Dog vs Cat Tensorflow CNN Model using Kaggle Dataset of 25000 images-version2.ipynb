{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part 0 - Importing the necessary libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(1024, activation='relu'))\n",
    "classifier.add(Dropout(0.20))\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including a few Augmentations\n",
    "trainval_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25,\n",
    "                                     horizontal_flip=True, vertical_flip=True, rotation_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18750 images belonging to 2 classes.\n",
      "Found 6250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = trainval_datagen.flow_from_directory('D:/Deep Learning & ML/Datasets/dogs-vs-cats/train',\n",
    "                                                   target_size=(64,64),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary',\n",
    "                                                   subset='training')\n",
    "validation_set = trainval_datagen.flow_from_directory('D:/Deep Learning & ML/Datasets/dogs-vs-cats/train',\n",
    "                                                   target_size=(64,64),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary',\n",
    "                                                   subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in training_set:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "586/586 [==============================] - 231s 395ms/step - loss: 0.6673 - accuracy: 0.5932 - val_loss: 0.5943 - val_accuracy: 0.6415\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 128s 219ms/step - loss: 0.6259 - accuracy: 0.6558 - val_loss: 0.5870 - val_accuracy: 0.6381\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 120s 205ms/step - loss: 0.5999 - accuracy: 0.6791 - val_loss: 0.6103 - val_accuracy: 0.7062\n",
      "Epoch 4/10\n",
      "586/586 [==============================] - 119s 203ms/step - loss: 0.5654 - accuracy: 0.7089 - val_loss: 0.4778 - val_accuracy: 0.7154\n",
      "Epoch 5/10\n",
      "586/586 [==============================] - 125s 214ms/step - loss: 0.5433 - accuracy: 0.7266 - val_loss: 0.5390 - val_accuracy: 0.7333\n",
      "Epoch 6/10\n",
      "586/586 [==============================] - 126s 216ms/step - loss: 0.5311 - accuracy: 0.7345 - val_loss: 0.5182 - val_accuracy: 0.7509\n",
      "Epoch 7/10\n",
      "586/586 [==============================] - 128s 219ms/step - loss: 0.5153 - accuracy: 0.7442 - val_loss: 0.5868 - val_accuracy: 0.7348\n",
      "Epoch 8/10\n",
      "586/586 [==============================] - 162s 276ms/step - loss: 0.5045 - accuracy: 0.7525 - val_loss: 0.4760 - val_accuracy: 0.7488\n",
      "Epoch 9/10\n",
      "586/586 [==============================] - 237s 405ms/step - loss: 0.5000 - accuracy: 0.7572 - val_loss: 0.4734 - val_accuracy: 0.7377\n",
      "Epoch 10/10\n",
      "586/586 [==============================] - 197s 337ms/step - loss: 0.4940 - accuracy: 0.7621 - val_loss: 0.4640 - val_accuracy: 0.7551\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit_generator(training_set,\n",
    "#                                 steps_per_epoch=500,\n",
    "                                epochs=10,\n",
    "                                validation_data=validation_set,\n",
    "                                validation_steps=150,\n",
    "                                verbose=1)\n",
    "\n",
    "classifier.save(\"dogcat_onkaggledata_model02.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "586/586 [==============================] - 136s 233ms/step - loss: 0.4835 - accuracy: 0.7684 - val_loss: 0.2987 - val_accuracy: 0.7531\n",
      "Epoch 2/5\n",
      "586/586 [==============================] - 133s 227ms/step - loss: 0.4789 - accuracy: 0.7719 - val_loss: 0.4394 - val_accuracy: 0.7361\n",
      "Epoch 3/5\n",
      "586/586 [==============================] - 132s 225ms/step - loss: 0.4701 - accuracy: 0.7730 - val_loss: 0.5473 - val_accuracy: 0.7641\n",
      "Epoch 4/5\n",
      "586/586 [==============================] - 132s 225ms/step - loss: 0.4680 - accuracy: 0.7757 - val_loss: 0.3465 - val_accuracy: 0.7784\n",
      "Epoch 5/5\n",
      "586/586 [==============================] - 128s 219ms/step - loss: 0.4599 - accuracy: 0.7858 - val_loss: 0.4023 - val_accuracy: 0.7592\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit_generator(training_set,\n",
    "#                                 steps_per_epoch=500,\n",
    "                                epochs=5,\n",
    "                                validation_data=validation_set,\n",
    "                                validation_steps=150,\n",
    "                                verbose=1)\n",
    "classifier.save(\"dogcat_onkaggledata_model02v2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              6423552   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,573,217\n",
      "Trainable params: 6,573,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('D:/Deep Learning & ML/Online Trainings/DLCVNLP (iNeuron)/mycodes/dogcat001/cat.jpg',\n",
    "                            target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "model = load_model(\"dogcat_onkaggledata_model02.h5\")\n",
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems model '01' is correctly predicting this as cat but not the models '02' and '02v2'.\n",
    "# Maybe few more channels in 2nd convolution or something else is needed to improve this further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
